{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "--W9CmMDa7mc",
        "outputId": "be5ac6fd-b561-4ba9-b453-835fba88b52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libclang-dev is already the newest version (1:14.0-55~exp2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "Collecting tokenizers==0.13.3\n",
            "  Using cached tokenizers-0.13.3.tar.gz (314 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tokenizers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting transformers==4.28.0\n",
            "  Using cached transformers-4.28.0-py3-none-any.whl.metadata (109 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.28.0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.28.0) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.28.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.28.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.28.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.28.0) (2.32.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n",
            "  Using cached tokenizers-0.13.3.tar.gz (314 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.28.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.28.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.28.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.28.0) (2025.11.12)\n",
            "Using cached transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "Building wheels for collected packages: tokenizers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Mount to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install libraries\n",
        "!apt-get update && apt-get install -y libclang-dev\n",
        "!pip install tokenizers==0.13.3\n",
        "!pip install transformers==4.28.0 torch torchaudio numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Paths\n",
        "zip_path = \"/content/drive/MyDrive/Plagiarism-Detection-System/data/processed_smp.zip\"\n",
        "extract_path = \"/content/data\"\n",
        "\n",
        "# Decompression\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Unzipping dataset...\")\n",
        "    !unzip -q \"{zip_path}\" -d \"{extract_path}\"\n",
        "    print(\"Done!\")\n",
        "else:\n",
        "    print(\"Files already extracted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVjKgCxtblQg",
        "outputId": "9a86c846-15cf-4bfe-e123-daec1237630a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping dataset...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import torchaudio.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, tracks_dir: str, audio_processor=None):\n",
        "        self.tracks_dir = tracks_dir\n",
        "        self.tracklist = sorted([\n",
        "            t for t in os.listdir(tracks_dir)\n",
        "            if os.path.isdir(os.path.join(tracks_dir, t)) and not t.startswith('.')\n",
        "        ])\n",
        "        self.audio_processor = audio_processor\n",
        "        self.sample_rate = None\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.tracklist)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
        "        audios = {}\n",
        "        track_name = self.tracklist[idx]\n",
        "        track_path = os.path.join(self.tracks_dir, track_name)\n",
        "\n",
        "        versions = sorted([\n",
        "            v for v in os.listdir(track_path)\n",
        "            if os.path.isdir(os.path.join(track_path, v)) and not v.startswith('.')\n",
        "        ])\n",
        "\n",
        "        for version in versions:\n",
        "            version_path = os.path.join(track_path, version)\n",
        "            files = sorted([f for f in os.listdir(version_path) if f.endswith('.wav')])\n",
        "\n",
        "            if not files: continue\n",
        "\n",
        "            audios[version] = []\n",
        "            for file in files:\n",
        "                file_path = os.path.join(version_path, file)\n",
        "\n",
        "                # ŒîŒπŒ±Œ≤Œ¨Œ∂ŒøœÖŒºŒµ ŒºŒµ soundfile\n",
        "                data, samplerate = sf.read(file_path)\n",
        "                self.sample_rate = samplerate\n",
        "\n",
        "                # Œ§Œø soundfile ŒµœÄŒπœÉœÑœÅŒ≠œÜŒµŒπ numpy array (Samples, Channels) ŒÆ (Samples,)\n",
        "                # Œ§Œø ŒºŒµœÑŒ±œÑœÅŒ≠œÄŒøœÖŒºŒµ œÉŒµ Tensor: (Channels, Samples)\n",
        "                waveform = torch.from_numpy(data).float()\n",
        "                if waveform.ndim == 1:\n",
        "                    waveform = waveform.unsqueeze(0) # Mono -> (1, Samples)\n",
        "                else:\n",
        "                    waveform = waveform.t() # Stereo -> (Channels, Samples)\n",
        "\n",
        "                audios[version].append(waveform)\n",
        "\n",
        "            # MERT Preprocessing\n",
        "            if self.audio_processor:\n",
        "                target_sr = self.audio_processor.sampling_rate\n",
        "                processed_audios = []\n",
        "                for waveform in audios[version]:\n",
        "                    if self.sample_rate is not None and self.sample_rate != target_sr:\n",
        "                        waveform = F.resample(waveform, int(self.sample_rate), target_sr)\n",
        "\n",
        "                    inputs = self.audio_processor(\n",
        "                        waveform.squeeze().numpy(),\n",
        "                        sampling_rate=target_sr,\n",
        "                        return_tensors=\"pt\"\n",
        "                    )[\"input_values\"].squeeze()\n",
        "                    processed_audios.append(inputs)\n",
        "\n",
        "                audios[version] = processed_audios\n",
        "\n",
        "        if audios:\n",
        "            min_frames = min([len(audios[v]) for v in audios.keys()])\n",
        "            for v in audios.keys():\n",
        "                audios[v] = audios[v][:min_frames]\n",
        "\n",
        "        return {'track': track_name, 'audios': audios}\n",
        "\n",
        "def audio_collate_fn(batch):\n",
        "    batch_dict = {}\n",
        "    max_len = 0\n",
        "    for item in batch:\n",
        "        for version in item[\"audios\"]:\n",
        "            for segment in item[\"audios\"][version]:\n",
        "                if segment.shape[-1] > max_len: max_len = segment.shape[-1]\n",
        "\n",
        "    for item in batch:\n",
        "        track_name = item[\"track\"]\n",
        "        batch_dict[track_name] = []\n",
        "        for version in item[\"audios\"]:\n",
        "            padded_segments = []\n",
        "            for segment in item[\"audios\"][version]:\n",
        "                pad_amount = max_len - segment.shape[-1]\n",
        "                padded_seg = torch.nn.functional.pad(segment, (0, pad_amount))\n",
        "                padded_segments.append(padded_seg)\n",
        "            batch_dict[track_name].append(torch.stack(padded_segments))\n",
        "    return batch_dict\n",
        "\n",
        "def create_audio_dataloader(tracks_dir, batch_size=1, num_workers=2, audio_processor=None):\n",
        "    dataset = AudioDataset(tracks_dir, audio_processor=audio_processor)\n",
        "    return DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, collate_fn=audio_collate_fn)"
      ],
      "metadata": {
        "id": "fvd5TVlQcDJH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLzCGeJ5f2rB",
        "outputId": "2411e3b0-2b50-4ba2-e243-ff54e17896a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import AutoModel, Wav2Vec2FeatureExtractor\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# ŒëŒΩŒ±Œ≥Œ∫Œ¨Œ∂ŒøœÖŒºŒµ œÑŒø torchaudio ŒΩŒ± œáœÅŒ∑œÉŒπŒºŒøœÄŒøŒπŒÆœÉŒµŒπ œÑŒø soundfile\n",
        "try:\n",
        "    import soundfile\n",
        "    torchaudio.set_audio_backend(\"soundfile\")\n",
        "    print(\"‚úÖ Audio backend set to: soundfile\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Could not set soundfile backend explicitly. Hoping for auto-detection.\")\n",
        "\n",
        "INPUT_DIR = \"/content/data/processed_smp\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Plagiarism-Detection-System/data/mert_embeddings\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def run_mert_extraction():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"üöÄ Using device: {device}\")\n",
        "\n",
        "    # Load Model\n",
        "    print(\"Loading MERT model...\")\n",
        "    processor = Wav2Vec2FeatureExtractor.from_pretrained(\"m-a-p/MERT-v1-95M\")\n",
        "    model = AutoModel.from_pretrained(\"m-a-p/MERT-v1-95M\", trust_remote_code=True).to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Time reduction layer\n",
        "    time_reduce = torch.nn.AvgPool1d(kernel_size=10, stride=10, count_include_pad=False)\n",
        "\n",
        "    # Dataloader\n",
        "    # Œ†ŒµœÅŒΩŒ¨ŒºŒµ œÑŒø processor Œ≥ŒπŒ± ŒΩŒ± Œ≥ŒØŒΩŒµœÑŒ±Œπ œÑŒø resampling ŒºŒ≠œÉŒ± œÉœÑŒø dataset\n",
        "    dataloader = create_audio_dataloader(INPUT_DIR, batch_size=1, audio_processor=processor)\n",
        "\n",
        "    print(f\"Starting extraction for {len(dataloader)} tracks...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            for track_name in batch.keys():\n",
        "                output_path = os.path.join(OUTPUT_DIR, f\"{track_name}.npy\")\n",
        "\n",
        "                if os.path.exists(output_path):\n",
        "                    continue\n",
        "\n",
        "                track_versions = []\n",
        "\n",
        "                for version_segments in batch[track_name]:\n",
        "                    version_segments = version_segments.to(device)\n",
        "\n",
        "                    # Pass through MERT\n",
        "                    hidden_states = model(version_segments, output_hidden_states=True).hidden_states\n",
        "\n",
        "                    # Select Layers (2, 5, 8, 11) & Reduce Time Dimension\n",
        "                    features = torch.stack(\n",
        "                        [time_reduce(h.detach()[:, :, :].permute(0,2,1)).permute(0,2,1) for h in hidden_states[2::3]],\n",
        "                        dim=1\n",
        "                    )\n",
        "\n",
        "                    track_versions.append(features.cpu().numpy())\n",
        "\n",
        "                final_array = np.array(track_versions)\n",
        "                np.save(output_path, final_array)\n",
        "\n",
        "    print(f\"\\n‚úÖ Extraction Complete! Saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "run_mert_extraction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrBQK3_kcX7w",
        "outputId": "c34f0ba0-e3a2-4239-af34-51e4368f8838"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Could not set soundfile backend explicitly. Hoping for auto-detection.\n",
            "üöÄ Using device: cuda\n",
            "Loading MERT model...\n",
            "Starting extraction for 158 tracks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 158/158 [08:42<00:00,  3.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Extraction Complete! Saved to: /content/drive/MyDrive/Plagiarism-Detection-System/data/mert_embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}